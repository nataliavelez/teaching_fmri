{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit teaching models to behavioral data\n",
    "Natalia VÃ©lez & Alicia Chen, November 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval as eval_tuple\n",
    "from scipy.stats import entropy\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import read_json, write_json, int_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load teaching problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [[0, 0, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 0, 0]],\n",
       " 'B': [[1, 1, 1, 0, 0, 0],\n",
       "  [1, 1, 1, 0, 0, 0],\n",
       "  [1, 1, 1, 1, 0, 0],\n",
       "  [0, 0, 1, 1, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0]],\n",
       " 'C': [[0, 0, 0, 1, 1, 1],\n",
       "  [0, 0, 0, 1, 1, 1],\n",
       "  [0, 0, 1, 1, 1, 1],\n",
       "  [0, 0, 1, 1, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0]],\n",
       " 'D': [[0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 1, 0, 0],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems = read_json('inputs/problems.json')\n",
    "problems[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load exclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 17]\n"
     ]
    }
   ],
   "source": [
    "excluded = np.loadtxt('../1_preprocessing/outputs/excluded_participants.txt', dtype=str)\n",
    "excluded = [int_extract('[0-9]+', s) for s in excluded]\n",
    "print(excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load teaching data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>run</th>\n",
       "      <th>block_idx</th>\n",
       "      <th>ex_idx</th>\n",
       "      <th>problem</th>\n",
       "      <th>example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  run  block_idx  ex_idx  problem  example\n",
       "0        1    1          0       0       22        8\n",
       "1        1    1          0       1       22       27\n",
       "3        1    1          1       0       18        3\n",
       "4        1    1          1       1       18       32\n",
       "5        1    1          1       2       18        7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_examples(e):\n",
    "    coords = eval_tuple(e)\n",
    "    idx = np.ravel_multi_index(coords, (6,6))\n",
    "    \n",
    "    return idx\n",
    "\n",
    "human_df = pd.read_csv('outputs/teaching_behavior.csv')\n",
    "human_df = human_df.drop(columns=['onset', 'order', 'rating']) # drop columns that are irrelevant for model\n",
    "human_df = human_df[~human_df.subject.isin(excluded)] # exclude wiggly participants\n",
    "human_df = human_df[~pd.isna(human_df.example)] # exclude trials where teachers failed to respond\n",
    "human_df['example'] = human_df.example.apply(read_examples)\n",
    "\n",
    "human_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert teaching problem (dict) into dataframe of coordinates x hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypotheses_dataframe(hypotheses):\n",
    "    '''\n",
    "    general method: converts (4,6,6) array (used, e.g., in teaching problems, priors, etc.) \n",
    "    into an examples x hypotheses dataframe\n",
    "    '''\n",
    "    \n",
    "    hypotheses_flat = np.reshape(hypotheses, (hypotheses.shape[0], hypotheses.shape[1]*hypotheses.shape[2])) #  flatten 3d => 2d array\n",
    "\n",
    "    ### reshape into dataframe of coordinates x hypotheses\n",
    "    df = pd.DataFrame(hypotheses_flat).stack().rename_axis(['hypothesis', 'idx']).reset_index(name='val')\n",
    "    \n",
    "    # name hypotheses\n",
    "    df['hypothesis'] = pd.Categorical(df.hypothesis)\n",
    "    df['hypothesis'] = df.hypothesis.cat.rename_categories(['A', 'B', 'C', 'D'])\n",
    "    df['hypothesis'] = df['hypothesis'].astype('object')\n",
    "    \n",
    "    # spread each hypothesis into its own column\n",
    "    df = df.pivot(index='idx', columns='hypothesis', values='val')\n",
    "    df = df[df.sum(axis=1) > 0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def problem_df(prob_idx):\n",
    "    '''\n",
    "    reads problem and converts to dataframe\n",
    "    '''\n",
    "    prob = problems[prob_idx]\n",
    "    hypotheses = np.array(list(prob.values())) # read hypothesis space\n",
    "    df = hypotheses_dataframe(hypotheses)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hypothesis</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hypothesis  A  B  C  D\n",
       "idx                   \n",
       "9           1  1  1  0\n",
       "10          0  1  0  0\n",
       "14          1  1  1  0\n",
       "15          1  1  1  0\n",
       "16          0  1  0  0\n",
       "19          1  1  1  1\n",
       "20          1  1  1  1\n",
       "21          1  1  1  1\n",
       "22          0  1  0  0\n",
       "25          0  1  1  1\n",
       "26          0  1  1  1\n",
       "27          0  1  1  1\n",
       "28          0  1  0  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_df(20) # let's test it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns a matrix of examples x hypotheses, where each entry indicates whether a given hypothesis is consistent with this next example *and all examples that came before it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_consistent_examples(prob_idx, past_examples=[]):\n",
    "    example_space = problem_df(prob_idx)\n",
    "    possible_examples = example_space.copy()\n",
    "    \n",
    "    for ex in past_examples:\n",
    "        consistent_with_past = possible_examples.loc[ex] # which hypotheses did this hypothesis rule out?\n",
    "        possible_examples = possible_examples.drop(ex) # drop past examples from consideration\n",
    "        \n",
    "        # drop hypotheses that are incompatible with this past example\n",
    "        possible_examples = possible_examples.mul(consistent_with_past, axis=1)\n",
    "        possible_examples = possible_examples[possible_examples.columns[possible_examples.sum()>0]]\n",
    "        \n",
    "    return possible_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hypothesis</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.104478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.104478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.104478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.104478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.089552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.089552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hypothesis         A         B         D\n",
       "idx                                     \n",
       "1           0.076923  0.074468  0.000000\n",
       "2           0.000000  0.000000  0.089552\n",
       "3           0.000000  0.000000  0.089552\n",
       "4           0.076923  0.074468  0.000000\n",
       "7           0.065934  0.063830  0.000000\n",
       "9           0.054945  0.053191  0.074627\n",
       "10          0.065934  0.063830  0.000000\n",
       "13          0.065934  0.063830  0.104478\n",
       "16          0.065934  0.063830  0.104478\n",
       "19          0.065934  0.063830  0.104478\n",
       "22          0.065934  0.074468  0.104478\n",
       "25          0.065934  0.053191  0.000000\n",
       "26          0.054945  0.042553  0.074627\n",
       "27          0.054945  0.000000  0.074627\n",
       "28          0.065934  0.063830  0.000000\n",
       "31          0.076923  0.063830  0.000000\n",
       "32          0.000000  0.053191  0.089552\n",
       "33          0.000000  0.053191  0.089552\n",
       "34          0.076923  0.074468  0.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_edge_prior(22, [8]) # let's test it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return full belief distribution (used to generate model predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_belief(nonzero_belief):\n",
    "    belief = nonzero_belief.reindex(['A', 'B', 'C', 'D'], fill_value=0)\n",
    "    return belief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a pandas dataseries to a list of tuples containing `(index, value)` (we're going to use this to save model predictions to JSON files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series2tuple(s):\n",
    "    return list(zip(bs.index,s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Strong sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the sampling method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strong_sampling(prob_idx, past_examples=[]):\n",
    "    '''\n",
    "    Input: Index of problem (as it appears in \"problems\" list)\n",
    "    Output: Dataframe of the probability of selecting the data (idx), given the hypothesis (A, B, C, D)\n",
    "    '''\n",
    "    # find available examples\n",
    "    available_examples = filter_consistent_examples(prob_idx, past_examples=past_examples)\n",
    "\n",
    "    # select uniformly among available examples\n",
    "    pD = available_examples.div(available_examples.sum(axis=0), axis=1)\n",
    "    \n",
    "    return pD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main method: Compute likelihood of data under strong sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_strong_sampling(group):\n",
    "    model_outputs = []\n",
    "    examples = []\n",
    "    \n",
    "    # initialize belief distribution\n",
    "    # (uniform prior over hypotheses)\n",
    "    belief = np.ones(4)*.25\n",
    "    belief_in_true = belief[0]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        ex = row.example\n",
    "        # likelihood of observed data, assuming strong sampling\n",
    "        strong_pD = strong_sampling(row.problem, past_examples=examples)\n",
    "        out = row.copy()\n",
    "        out['model'] = 'strong'\n",
    "        out['lik'] = strong_pD['A'].loc[ex] # likelihood of selected example\n",
    "        out['pD'] = series2tuple(strong_pD['A']) # full sampling distribution\n",
    "        \n",
    "        # learner's posterior belief given the data\n",
    "        strong_pH = strong_pD.div(strong_pD.sum(axis=1), axis=0)\n",
    "        new_belief = full_belief(strong_pH.loc[ex])\n",
    "        out['pTrue'] = strong_pH['A'].loc[ex] # probability of true hypotheses\n",
    "        out['pH'] = series2tuple(new_belief) # full belief distribution\n",
    "        out['entropy'] = entropy(new_belief.values) # entropy of belief distribution\n",
    "        \n",
    "        # change in beliefs\n",
    "        out['delta'] = new_belief['A'] - belief_in_true\n",
    "        out['KL'] = entropy(new_belief.values, belief)\n",
    "        belief = new_belief.values # change values for next round\n",
    "        belief_in_true = belief[0]\n",
    "        \n",
    "        out = out.to_dict()\n",
    "        examples.append(ex)\n",
    "        model_outputs.append(out)\n",
    "    \n",
    "    return model_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through behavioral data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL': 0.2998411459755585,\n",
      " 'block_idx': 0,\n",
      " 'delta': 0.05538922155688625,\n",
      " 'entropy': 1.0864532151443322,\n",
      " 'ex_idx': 0,\n",
      " 'example': 8,\n",
      " 'lik': 0.0625,\n",
      " 'model': 'strong',\n",
      " 'pD': [(1, 0.0625),\n",
      "        (2, 0.0),\n",
      "        (3, 0.0),\n",
      "        (4, 0.0625),\n",
      "        (7, 0.0625),\n",
      "        (8, 0.0625),\n",
      "        (9, 0.0625),\n",
      "        (10, 0.0625),\n",
      "        (13, 0.0625),\n",
      "        (16, 0.0625),\n",
      "        (19, 0.0625),\n",
      "        (22, 0.0625),\n",
      "        (25, 0.0625),\n",
      "        (26, 0.0625),\n",
      "        (27, 0.0625),\n",
      "        (28, 0.0625),\n",
      "        (31, 0.0625),\n",
      "        (32, 0.0),\n",
      "        (33, 0.0),\n",
      "        (34, 0.0625)],\n",
      " 'pH': [('A', 0.30538922155688625),\n",
      "        ('B', 0.2874251497005988),\n",
      "        ('C', 0.0),\n",
      "        ('D', 0.40718562874251496)],\n",
      " 'pTrue': 0.30538922155688625,\n",
      " 'problem': 22,\n",
      " 'run': 1,\n",
      " 'subject': 1}\n"
     ]
    }
   ],
   "source": [
    "strong_predictions = []\n",
    "for name, group in human_df.groupby(['subject', 'run', 'block_idx']):\n",
    "    pred = fit_strong_sampling(group)\n",
    "    strong_predictions += pred\n",
    "    \n",
    "pprint.pprint(strong_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(strong_predictions, 'outputs/model_predictions_strong.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Spatial bias model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the sampling method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatially_biased_sampling(prob_idx, past_examples=[]):\n",
    "    '''\n",
    "    This spatially-biased method places greater weight on selecting examples that \n",
    "    have fewer neighbors (i.e., an \"edge prior\")\n",
    "    '''    \n",
    "    # read hypothesis space\n",
    "    prob = problems[prob_idx]\n",
    "    hypothesis_space = np.array(list(prob.values()))\n",
    "\n",
    "    # assign weight to each square based on number of empty spaces\n",
    "    kernel = np.array([\n",
    "        [1,1,1],\n",
    "        [1,0,1],\n",
    "        [1,1,1]\n",
    "    ]) # convolution kernel (used to count # of neighbors)\n",
    "\n",
    "    n_neighbors = np.zeros(hypothesis_space.shape)\n",
    "    for i in range(hypothesis_space.shape[0]):\n",
    "        n_neighbors[i,:,:] = convolve(hypothesis_space[i,:,:], kernel, mode='constant')\n",
    "    edge_weight = 8-n_neighbors\n",
    "    edge_weight = edge_weight+1 # don't entirely rule out \"landlocked\" squares    \n",
    "\n",
    "    # keep only examples that are consistent with the ones that came before\n",
    "    all_squares = hypotheses_dataframe(edge_weight)\n",
    "    valid_examples = filter_consistent_examples(prob_idx, past_examples)\n",
    "    edge_df = all_squares[all_squares.index.isin(valid_examples.index)].copy()\n",
    "    edge_df = valid_examples.mul(edge_df[valid_examples.columns])\n",
    "    \n",
    "    # normalize\n",
    "    edge_df = edge_df.div(edge_df.sum(axis=0), axis=1)\n",
    "    return edge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate spatial bias predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_spatial_bias(group):\n",
    "    model_outputs = []\n",
    "    examples = []\n",
    "    \n",
    "    # initialize belief distribution\n",
    "    # (uniform prior over hypotheses)\n",
    "    belief = np.ones(4)*.25\n",
    "    belief_in_true = belief[0]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        ex = row.example\n",
    "        # likelihood of observed data, assuming strong sampling\n",
    "        bias_pD = spatially_biased_sampling(row.problem, past_examples=examples)\n",
    "        out = row.copy()\n",
    "        out['model'] = 'spatial_bias'\n",
    "        out['lik'] = bias_pD['A'].loc[ex] # likelihood of selected example\n",
    "        out['pD'] = series2tuple(bias_pD['A']) # full sampling distribution\n",
    "        \n",
    "        # learner's posterior belief given the data\n",
    "        bias_pH = bias_pD.div(bias_pD.sum(axis=1), axis=0)\n",
    "        new_belief = full_belief(bias_pH.loc[ex])\n",
    "        out['pTrue'] = bias_pH['A'].loc[ex] # probability of true hypotheses\n",
    "        out['pH'] = series2tuple(new_belief) # full belief distribution\n",
    "        out['entropy'] = entropy(new_belief.values) # entropy of belief distribution\n",
    "        \n",
    "        # change in beliefs\n",
    "        out['delta'] = new_belief['A'] - belief_in_true\n",
    "        out['KL'] = entropy(new_belief.values, belief)\n",
    "        belief = new_belief.values # change values for next round\n",
    "        belief_in_true = belief[0]\n",
    "        \n",
    "        out = out.to_dict()\n",
    "        examples.append(ex)\n",
    "        model_outputs.append(out)\n",
    "    \n",
    "    return model_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through behavioral data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL': 0.2985487019218349,\n",
      " 'block_idx': 0,\n",
      " 'delta': 0.05275229357798167,\n",
      " 'entropy': 1.0877456591980557,\n",
      " 'ex_idx': 0,\n",
      " 'example': 8,\n",
      " 'lik': 0.052083333333333336,\n",
      " 'model': 'spatial_bias',\n",
      " 'pD': [(1, 0.07291666666666667),\n",
      "        (2, 0.0),\n",
      "        (3, 0.0),\n",
      "        (4, 0.07291666666666667),\n",
      "        (7, 0.0625),\n",
      "        (8, 0.052083333333333336),\n",
      "        (9, 0.052083333333333336),\n",
      "        (10, 0.0625),\n",
      "        (13, 0.0625),\n",
      "        (16, 0.0625),\n",
      "        (19, 0.0625),\n",
      "        (22, 0.0625),\n",
      "        (25, 0.0625),\n",
      "        (26, 0.052083333333333336),\n",
      "        (27, 0.052083333333333336),\n",
      "        (28, 0.0625),\n",
      "        (31, 0.07291666666666667),\n",
      "        (32, 0.0),\n",
      "        (33, 0.0),\n",
      "        (34, 0.07291666666666667)],\n",
      " 'pH': [('A', 0.30275229357798167),\n",
      "        ('B', 0.2935779816513761),\n",
      "        ('C', 0.0),\n",
      "        ('D', 0.4036697247706422)],\n",
      " 'pTrue': 0.30275229357798167,\n",
      " 'problem': 22,\n",
      " 'run': 1,\n",
      " 'subject': 1}\n"
     ]
    }
   ],
   "source": [
    "biased_predictions = []\n",
    "for name, group in human_df.groupby(['subject', 'run', 'block_idx']):\n",
    "    pred = fit_spatial_bias(group)\n",
    "    biased_predictions += pred\n",
    "    \n",
    "pprint.pprint(biased_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(biased_predictions, 'outputs/model_predictions_spatialbias.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Pedagogical sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the belief updating method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pedagogical_belief_updating(prob_idx, past_examples, last_pH):\n",
    "    '''\n",
    "    In sequential cooperative Bayesian inference (Wang, Wang & Shafto, 2020), \n",
    "    the posterior on the last trial is then passed on as the prior for the next trial. \n",
    "    \n",
    "    Or, in other words... \"yesterday's posterior is tomorrow's prior\"\n",
    "    This function then updates the learner's beliefs according to:\n",
    "    P(H|D) = P(H)P(D|H) / P(D)\n",
    "    '''\n",
    "    # drop past examples (can't be repeated)\n",
    "    pD = filter_consistent_examples(prob_idx, past_examples=past_examples)\n",
    "    pD = pD.div(pD.sum(axis=0), axis=1) # normalize columns\n",
    "    \n",
    "    # update pH\n",
    "    last_example = past_examples[-1]\n",
    "    yesterdays_posterior = last_pH.loc[last_example]\n",
    "    prior_unnorm = pD.mul(yesterdays_posterior, axis=1)\n",
    "    tomorrows_prior = prior_unnorm.div(prior_unnorm.sum(axis=1), axis=0)\n",
    "    \n",
    "    # drop hypotheses that are incompatible with past examples\n",
    "    # (makes some of the math nicer - otherwise we'll run into divide-by-0 errors in Sinkhorn scaling)\n",
    "    tomorrows_prior = tomorrows_prior[tomorrows_prior.columns[tomorrows_prior.sum()>0]]\n",
    "    \n",
    "    return tomorrows_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the sampling method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pedagogical_sampling(prob_idx, past_examples=[], last_pH=None, nIter=10):\n",
    "        \n",
    "    if len(past_examples):\n",
    "        pH = pedagogical_belief_updating(prob_idx, past_examples, last_pH)\n",
    "    # else: start from a uniform prior\n",
    "    else:\n",
    "        hypothesis_space = problem_df(prob_idx)\n",
    "        uniform_prior = hypothesis_space.div(hypothesis_space.sum(axis=1), axis=0)\n",
    "        pH = uniform_prior\n",
    "        \n",
    "    # ~ recursive reasoning ~\n",
    "    for _ in range(nIter):\n",
    "        pD = pH.div(pH.sum(axis=0), axis=1)\n",
    "        pH = pD.div(pD.sum(axis=1), axis=0)\n",
    "        \n",
    "    return pD, pH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main method: Compute likelihood of data under pedagogical sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pedagogical_sampling(group, nIter=20):\n",
    "    model_outputs = []\n",
    "    \n",
    "    # initialize inputs to sampler\n",
    "    examples = []\n",
    "    pH = None\n",
    "    pD = None\n",
    "    \n",
    "    # initialize belief distribution\n",
    "    # (uniform prior over hypotheses)\n",
    "    belief = np.ones(4)*.25\n",
    "    belief_in_true = belief[0]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        ex = row.example\n",
    "        out = row.copy()\n",
    "        out['model'] = 'pedagogical'\n",
    "\n",
    "        # likelihood of observed data, assuming pedagogical sampling\n",
    "        pD, pH = pedagogical_sampling(row.problem, past_examples=examples, last_pH=pH, nIter=nIter)\n",
    "        out['lik'] = pD['A'].loc[ex]\n",
    "        out['pD'] = series2tuple(pD['A']) # full sampling distribution\n",
    "        \n",
    "        # learner's posterior belief given the data\n",
    "        new_belief = full_belief(pH.loc[ex])\n",
    "        out['pTrue'] = new_belief['A']\n",
    "        out['pH'] = series2tuple(new_belief) # full belief distribution\n",
    "        out['entropy'] = entropy(new_belief.values) # entropy of belief distribution\n",
    "        \n",
    "        # change in beliefs\n",
    "        out['delta'] = new_belief['A'] - belief_in_true\n",
    "        out['KL'] = entropy(new_belief.values, belief)\n",
    "        belief = new_belief.values # change values for next round\n",
    "        belief_in_true = belief[0]\n",
    "        \n",
    "        out = out.to_dict()\n",
    "        examples.append(ex)\n",
    "        model_outputs.append(out)\n",
    "        \n",
    "    return model_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through behavioral data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL': 0.2973894774766346,\n",
      " 'block_idx': 0,\n",
      " 'delta': 0.06966637719365176,\n",
      " 'entropy': 1.0889048836432562,\n",
      " 'ex_idx': 0,\n",
      " 'example': 8,\n",
      " 'lik': 0.06393328805971461,\n",
      " 'model': 'pedagogical',\n",
      " 'pD': [(1, 0.07050694086392065),\n",
      "        (2, 0.0),\n",
      "        (3, 0.0),\n",
      "        (4, 0.07050694086392065),\n",
      "        (7, 0.07050694086392065),\n",
      "        (8, 0.06393328805971461),\n",
      "        (9, 0.06393328805971461),\n",
      "        (10, 0.07050694086392065),\n",
      "        (13, 0.04906615817640507),\n",
      "        (16, 0.04906615817640507),\n",
      "        (19, 0.04906615817640507),\n",
      "        (22, 0.04906615817640507),\n",
      "        (25, 0.07050694086392065),\n",
      "        (26, 0.04906615817640507),\n",
      "        (27, 0.06274710608717998),\n",
      "        (28, 0.07050694086392065),\n",
      "        (31, 0.07050694086392065),\n",
      "        (32, 0.0),\n",
      "        (33, 0.0),\n",
      "        (34, 0.07050694086392065)],\n",
      " 'pH': [('A', 0.31966637719365176),\n",
      "        ('B', 0.28409742653588654),\n",
      "        ('C', 0.0),\n",
      "        ('D', 0.3962361962704616)],\n",
      " 'pTrue': 0.31966637719365176,\n",
      " 'problem': 22,\n",
      " 'run': 1,\n",
      " 'subject': 1}\n"
     ]
    }
   ],
   "source": [
    "pedagogical_predictions = []\n",
    "nIter=10\n",
    "for name, group in human_df.groupby(['subject', 'run', 'block_idx']):\n",
    "    pred = fit_pedagogical_sampling(group, nIter=nIter)\n",
    "    pedagogical_predictions += pred\n",
    "    \n",
    "pprint.pprint(pedagogical_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model_predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(pedagogical_predictions, 'outputs/model_predictions_pedagogical_n%i.json' % nIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Pedagogical sampling + spatial bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belief updating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_pedagogical_update(prob_idx, past_examples, last_pH):\n",
    "    '''\n",
    "    In sequential cooperative Bayesian inference (Wang, Wang & Shafto, 2020), \n",
    "    the posterior on the last trial is then passed on as the prior for the next trial. \n",
    "    \n",
    "    Or, in other words... \"yesterday's posterior is tomorrow's prior\"\n",
    "    This function then updates the learner's beliefs according to:\n",
    "    P(H|D) = P(H)P(D|H) / P(D)\n",
    "    \n",
    "    This function differs from the pure pedagogical belief updating in that\n",
    "    p(d|h) is grounded in a spatially biased prior, rather than a uniform one\n",
    "    '''\n",
    "    # drop past examples (can't be repeated)\n",
    "    pD = spatially_biased_sampling(prob_idx, past_examples)\n",
    "    \n",
    "    # update pH\n",
    "    last_example = past_examples[-1]\n",
    "    yesterdays_posterior = last_pH.loc[last_example]\n",
    "    prior_unnorm = pD.mul(yesterdays_posterior, axis=1)\n",
    "    tomorrows_prior = prior_unnorm.div(prior_unnorm.sum(axis=1), axis=0)\n",
    "    \n",
    "    # drop hypotheses that are incompatible with past examples\n",
    "    # (makes some of the math nicer - otherwise we'll run into divide-by-0 errors in Sinkhorn scaling)\n",
    "    tomorrows_prior = tomorrows_prior[tomorrows_prior.columns[tomorrows_prior.sum()>0]]\n",
    "    \n",
    "    return tomorrows_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the sampling method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_pedagogical_sampling(prob_idx, past_examples=[], last_pH=None, nIter=10):\n",
    "        \n",
    "    if len(past_examples):\n",
    "        pH = spatial_pedagogical_update(prob_idx, past_examples, last_pH)\n",
    "    # else: start from a spatially biased prior\n",
    "    else:\n",
    "        pD = spatially_biased_sampling(prob_idx)\n",
    "        pH = pD.div(pD.sum(axis=1), axis=0)\n",
    "        \n",
    "    # ~ recursive reasoning ~\n",
    "    for _ in range(nIter):\n",
    "        pD = pH.div(pH.sum(axis=0), axis=1)\n",
    "        pH = pD.div(pD.sum(axis=1), axis=0)\n",
    "        \n",
    "    return pD, pH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit to behavioral data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_spatial_pedagogical_sampling(group, nIter=20):\n",
    "    model_outputs = []\n",
    "    \n",
    "    # initialize inputs to sampler\n",
    "    examples = []\n",
    "    pH = None\n",
    "    pD = None\n",
    "    \n",
    "    # initialize belief distribution\n",
    "    # (uniform prior over hypotheses)\n",
    "    belief = np.ones(4)*.25\n",
    "    belief_in_true = belief[0]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        ex = row.example\n",
    "        out = row.copy()\n",
    "        out['model'] = 'pedagogical_plus_spatial_bias'\n",
    "\n",
    "        # likelihood of observed data, assuming pedagogical sampling\n",
    "        pD, pH = spatial_pedagogical_sampling(row.problem, past_examples=examples, last_pH=pH, nIter=nIter)\n",
    "        out['lik'] = pD['A'].loc[ex]\n",
    "        out['pD'] = series2tuple(pD['A']) # full sampling distribution\n",
    "        \n",
    "        # learner's posterior belief given the data\n",
    "        new_belief = full_belief(pH.loc[ex])\n",
    "        out['pTrue'] = new_belief['A']\n",
    "        out['pH'] = series2tuple(new_belief) # full belief distribution\n",
    "        out['entropy'] = entropy(new_belief.values) # entropy of belief distribution\n",
    "        \n",
    "        # change in beliefs\n",
    "        out['delta'] = new_belief['A'] - belief_in_true\n",
    "        out['KL'] = entropy(new_belief.values, belief)\n",
    "        belief = new_belief.values # change values for next round\n",
    "        belief_in_true = belief[0]\n",
    "        \n",
    "        out = out.to_dict()\n",
    "        examples.append(ex)\n",
    "        model_outputs.append(out)\n",
    "        \n",
    "    return model_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through behavioral data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL': 0.29226158189876716,\n",
      " 'block_idx': 0,\n",
      " 'delta': 0.0741031974293132,\n",
      " 'entropy': 1.0940327792211237,\n",
      " 'ex_idx': 0,\n",
      " 'example': 8,\n",
      " 'lik': 0.06482063340722197,\n",
      " 'model': 'pedagogical_plus_spatial_bias',\n",
      " 'pD': [(1, 0.07011358450770017),\n",
      "        (2, 0.0),\n",
      "        (3, 0.0),\n",
      "        (4, 0.07011358450770017),\n",
      "        (7, 0.0701135845077002),\n",
      "        (8, 0.06482063340722197),\n",
      "        (9, 0.06482063340722197),\n",
      "        (10, 0.0701135845077002),\n",
      "        (13, 0.04584825312310762),\n",
      "        (16, 0.04584825312310762),\n",
      "        (19, 0.04753448667267756),\n",
      "        (22, 0.04585600269502843),\n",
      "        (25, 0.07411506653800348),\n",
      "        (26, 0.052231634711429796),\n",
      "        (27, 0.0647278405889353),\n",
      "        (28, 0.0701135845077002),\n",
      "        (31, 0.07351568868706516),\n",
      "        (32, 0.0),\n",
      "        (33, 0.0),\n",
      "        (34, 0.07011358450770017)],\n",
      " 'pH': [('A', 0.3241031974293132),\n",
      "        ('B', 0.2994861975027223),\n",
      "        ('C', 0.0),\n",
      "        ('D', 0.3764106050679644)],\n",
      " 'pTrue': 0.3241031974293132,\n",
      " 'problem': 22,\n",
      " 'run': 1,\n",
      " 'subject': 1}\n"
     ]
    }
   ],
   "source": [
    "spatial_pedagogical_predictions = []\n",
    "nIter=10\n",
    "for name, group in human_df.groupby(['subject', 'run', 'block_idx']):\n",
    "    pred = fit_spatial_pedagogical_sampling(group, nIter=nIter)\n",
    "    spatial_pedagogical_predictions += pred\n",
    "    \n",
    "pprint.pprint(spatial_pedagogical_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(spatial_pedagogical_predictions, 'outputs/model_predictions_spatialpedagogical_n%i.json' % nIter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py3]",
   "language": "python",
   "name": "conda-env-.conda-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
