{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit teaching models to behavioral data\n",
    "Natalia VÃ©lez & Alicia Chen, November 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval as eval_tuple\n",
    "from scipy.stats import entropy\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import read_json, write_json, int_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load teaching problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [[0, 0, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 0, 0]],\n",
       " 'B': [[1, 1, 1, 0, 0, 0],\n",
       "  [1, 1, 1, 0, 0, 0],\n",
       "  [1, 1, 1, 1, 0, 0],\n",
       "  [0, 0, 1, 1, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0]],\n",
       " 'C': [[0, 0, 0, 1, 1, 1],\n",
       "  [0, 0, 0, 1, 1, 1],\n",
       "  [0, 0, 1, 1, 1, 1],\n",
       "  [0, 0, 1, 1, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0]],\n",
       " 'D': [[0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 1, 0, 0],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems = read_json('inputs/problems.json')\n",
    "problems[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load exclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 17]\n"
     ]
    }
   ],
   "source": [
    "excluded = np.loadtxt('../1_preprocessing/outputs/excluded_participants.txt', dtype=str)\n",
    "excluded = [int_extract('[0-9]+', s) for s in excluded]\n",
    "print(excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load teaching data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>run</th>\n",
       "      <th>block_idx</th>\n",
       "      <th>ex_idx</th>\n",
       "      <th>problem</th>\n",
       "      <th>example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  run  block_idx  ex_idx  problem  example\n",
       "0        1    1          0       0       22        8\n",
       "1        1    1          0       1       22       27\n",
       "3        1    1          1       0       18        3\n",
       "4        1    1          1       1       18       32\n",
       "5        1    1          1       2       18        7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_examples(e):\n",
    "    coords = eval_tuple(e)\n",
    "    idx = np.ravel_multi_index(coords, (6,6))\n",
    "    \n",
    "    return idx\n",
    "\n",
    "human_df = pd.read_csv('outputs/teaching_behavior.csv')\n",
    "human_df = human_df.drop(columns=['onset', 'order', 'rating']) # drop columns that are irrelevant for model\n",
    "human_df = human_df[~human_df.subject.isin(excluded)] # exclude wiggly participants\n",
    "human_df = human_df[~pd.isna(human_df.example)] # exclude trials where teachers failed to respond\n",
    "human_df['example'] = human_df.example.apply(read_examples)\n",
    "\n",
    "human_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function: Convert problem into dataframe of coordinates x hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem_df(prob_idx):\n",
    "    prob = problems[prob_idx]\n",
    "    hypotheses = np.array(list(prob.values())) # read hypothesis space\n",
    "    hypotheses_flat = np.reshape(hypotheses, (hypotheses.shape[0], hypotheses.shape[1]*hypotheses.shape[2])) #  flatten 3d => 2d array\n",
    "\n",
    "    ### reshape into dataframe of coordinates x hypotheses\n",
    "    df = pd.DataFrame(hypotheses_flat).stack().rename_axis(['hypothesis', 'idx']).reset_index(name='val')\n",
    "    \n",
    "    # name hypotheses\n",
    "    df['hypothesis'] = pd.Categorical(df.hypothesis)\n",
    "    df['hypothesis'] = df.hypothesis.cat.rename_categories(['A', 'B', 'C', 'D'])\n",
    "    df['hypothesis'] = df['hypothesis'].astype('object')\n",
    "    \n",
    "    # spread each hypothesis into its own column\n",
    "    df = df.pivot(index='idx', columns='hypothesis', values='val')\n",
    "    df = df[df.sum(axis=1) > 0]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hypothesis</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hypothesis  A  B  C  D\n",
       "idx                   \n",
       "9           1  1  1  0\n",
       "10          0  1  0  0\n",
       "14          1  1  1  0\n",
       "15          1  1  1  0\n",
       "16          0  1  0  0\n",
       "19          1  1  1  1\n",
       "20          1  1  1  1\n",
       "21          1  1  1  1\n",
       "22          0  1  0  0\n",
       "25          0  1  1  1\n",
       "26          0  1  1  1\n",
       "27          0  1  1  1\n",
       "28          0  1  0  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_df(20) # let's test it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function: Returns a matrix of examples x hypotheses, where each entry indicates whether a given hypothesis is consistent with this next example *and all examples that came before it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_consistent_examples(prob_idx, past_examples=[]):\n",
    "    example_space = problem_df(prob_idx)\n",
    "    possible_examples = example_space.copy()\n",
    "    \n",
    "    for ex in past_examples:\n",
    "        consistent_with_past = possible_examples.loc[ex] # which hypotheses did this hypothesis rule out?\n",
    "        possible_examples = possible_examples.drop(ex) # drop past examples from consideration\n",
    "        \n",
    "        # drop hypotheses that are incompatible with this past example\n",
    "        possible_examples = possible_examples.mul(consistent_with_past, axis=1)\n",
    "        possible_examples = possible_examples[possible_examples.columns[possible_examples.sum()>0]]\n",
    "        \n",
    "    return possible_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function: Condition subsequent examples on past examples (used in pedagogical sampling predictions)\n",
    "\n",
    "<div style='padding:10px;border-radius:5px;background-color:#9fd7f5'><strong>Warning:</strong> This is a hacky solution for now. Check the math to make sure it's justified?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_on_past(prob_idx, pH_0, past_examples):\n",
    "    available_examples = filter_consistent_examples(prob_idx, past_examples)\n",
    "    pH_conditional = available_examples.mul(pH_0)\n",
    "    pH_conditional = pH_conditional.dropna(axis=0, how='all') # drop past examples\n",
    "    pH_conditional = pH_conditional.dropna(axis=1, how='all') # drop hypotheses that are contradicted by past examples\n",
    "    pH_conditional = pH_conditional.div(pH_conditional.sum(axis=1), axis=0) # re-normalize\n",
    "    \n",
    "    return pH_conditional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function: Return full belief distribution (used to generate model predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_belief(nonzero_belief):\n",
    "    belief = nonzero_belief.reindex(['A', 'B', 'C', 'D'], fill_value=0)\n",
    "    return belief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function: Convert a pandas dataseries to a list of tuples containing `(index, value)` (we're going to use this to save model predictions to JSON files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series2tuple(s):\n",
    "    return list(zip(s.index,s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Strong sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the sampling method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strong_sampling(prob_idx, past_examples=[]):\n",
    "    '''\n",
    "    Input: Index of problem (as it appears in \"problems\" list)\n",
    "    Output: Dataframe of the probability of selecting the data (idx), given the hypothesis (A, B, C, D)\n",
    "    '''\n",
    "    # find available examples\n",
    "    available_examples = filter_consistent_examples(prob_idx, past_examples=past_examples)\n",
    "\n",
    "    # select uniformly among available examples\n",
    "    pD = available_examples.div(available_examples.sum(axis=0), axis=1)\n",
    "    \n",
    "    return pD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main method: Compute likelihood of data under strong sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_strong_sampling(group):\n",
    "    model_outputs = []\n",
    "    examples = []\n",
    "    \n",
    "    # initialize belief distribution\n",
    "    # (uniform prior over hypotheses)\n",
    "    belief = np.ones(4)*.25\n",
    "    belief_in_true = belief[0]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        ex = row.example\n",
    "        # likelihood of observed data, assuming strong sampling\n",
    "        strong_pD = strong_sampling(row.problem, past_examples=examples)\n",
    "        out = row.copy()\n",
    "        out['model'] = 'strong'\n",
    "        out['lik'] = strong_pD['A'].loc[ex] # likelihood of selected example\n",
    "        out['pD'] = series2tuple(strong_pD['A']) # full sampling distribution\n",
    "        \n",
    "        # learner's posterior belief given the data\n",
    "        strong_pH = strong_pD.div(strong_pD.sum(axis=1), axis=0)\n",
    "        new_belief = full_belief(strong_pH.loc[ex])\n",
    "        out['pTrue'] = strong_pH['A'].loc[ex] # probability of true hypotheses\n",
    "        out['pH'] = series2tuple(new_belief) # full belief distribution\n",
    "        out['entropy'] = entropy(new_belief.values) # entropy of belief distribution\n",
    "        \n",
    "        # change in beliefs\n",
    "        out['delta'] = new_belief['A'] - belief_in_true\n",
    "        out['KL'] = entropy(new_belief.values, belief)\n",
    "        belief = new_belief.values # change values for next round\n",
    "        belief_in_true = belief[0]\n",
    "        \n",
    "        out = out.to_dict()\n",
    "        examples.append(ex)\n",
    "        model_outputs.append(out)\n",
    "    \n",
    "    return model_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through behavioral data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL': 0.2998411459755585,\n",
      " 'block_idx': 0,\n",
      " 'delta': 0.05538922155688625,\n",
      " 'entropy': 1.0864532151443322,\n",
      " 'ex_idx': 0,\n",
      " 'example': 8,\n",
      " 'lik': 0.0625,\n",
      " 'model': 'strong',\n",
      " 'pD': [(1, 0.0625),\n",
      "        (2, 0.0),\n",
      "        (3, 0.0),\n",
      "        (4, 0.0625),\n",
      "        (7, 0.0625),\n",
      "        (8, 0.0625),\n",
      "        (9, 0.0625),\n",
      "        (10, 0.0625),\n",
      "        (13, 0.0625),\n",
      "        (16, 0.0625),\n",
      "        (19, 0.0625),\n",
      "        (22, 0.0625),\n",
      "        (25, 0.0625),\n",
      "        (26, 0.0625),\n",
      "        (27, 0.0625),\n",
      "        (28, 0.0625),\n",
      "        (31, 0.0625),\n",
      "        (32, 0.0),\n",
      "        (33, 0.0),\n",
      "        (34, 0.0625)],\n",
      " 'pH': [('A', 0.30538922155688625),\n",
      "        ('B', 0.2874251497005988),\n",
      "        ('C', 0.0),\n",
      "        ('D', 0.40718562874251496)],\n",
      " 'pTrue': 0.30538922155688625,\n",
      " 'problem': 22,\n",
      " 'run': 1,\n",
      " 'subject': 1}\n"
     ]
    }
   ],
   "source": [
    "strong_predictions = []\n",
    "for name, group in human_df.groupby(['subject', 'run', 'block_idx']):\n",
    "    pred = fit_strong_sampling(group)\n",
    "    strong_predictions += pred\n",
    "    \n",
    "pprint.pprint(strong_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(strong_predictions, 'outputs/model_predictions_strong.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Pedagogical sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the sampling method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pedagogical_sampling(prob_idx, past_examples=[], pH_0=None, nIter=100):\n",
    "    \n",
    "    # condition pH on past examples\n",
    "    if len(past_examples):\n",
    "        pH = condition_on_past(prob_idx, pH_0, past_examples)\n",
    "    # else: start from a uniform prior\n",
    "    else:\n",
    "        hypothesis_space = problem_df(prob_idx)\n",
    "        uniform_prior = hypothesis_space.div(hypothesis_space.sum(axis=1), axis=0)\n",
    "        pH = uniform_prior\n",
    "        \n",
    "    # ~ recursive reasoning ~\n",
    "    for _ in range(nIter):\n",
    "        pD = pH.div(pH.sum(axis=0), axis=1)\n",
    "        pH = pD.div(pD.sum(axis=1), axis=0)\n",
    "        \n",
    "    return pD, pH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main method: Compute likelihood of data under pedagogical sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pedagogical_sampling(group, nIter=20):\n",
    "    model_outputs = []\n",
    "    \n",
    "    # initialize inputs to sampler\n",
    "    examples = []\n",
    "    pH = None\n",
    "    \n",
    "    # initialize belief distribution\n",
    "    # (uniform prior over hypotheses)\n",
    "    belief = np.ones(4)*.25\n",
    "    belief_in_true = belief[0]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        ex = row.example\n",
    "        out = row.copy()\n",
    "        out['model'] = 'pedagogical'\n",
    "\n",
    "        # likelihood of observed data, assuming pedagogical sampling\n",
    "        pedagogical_pD, pH = pedagogical_sampling(row.problem, past_examples=examples, pH_0=pH, nIter=nIter)\n",
    "        out['lik'] = pedagogical_pD['A'].loc[ex]\n",
    "        out['pD'] = series2tuple(pedagogical_pD['A']) # full sampling distribution\n",
    "        \n",
    "        # learner's posterior belief given the data\n",
    "        new_belief = full_belief(pH.loc[ex])\n",
    "        out['pTrue'] = new_belief['A']\n",
    "        out['pH'] = series2tuple(new_belief) # full belief distribution\n",
    "        out['entropy'] = entropy(new_belief.values) # entropy of belief distribution\n",
    "        \n",
    "        # change in beliefs\n",
    "        out['delta'] = new_belief['A'] - belief_in_true\n",
    "        out['KL'] = entropy(new_belief.values, belief)\n",
    "        belief = new_belief.values # change values for next round\n",
    "        belief_in_true = belief[0]\n",
    "        \n",
    "        out = out.to_dict()\n",
    "        examples.append(ex)\n",
    "        model_outputs.append(out)\n",
    "        \n",
    "    return model_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through behavioral data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL': 0.2973894774766346,\n",
      " 'block_idx': 0,\n",
      " 'delta': 0.06966637719365176,\n",
      " 'entropy': 1.0889048836432562,\n",
      " 'ex_idx': 0,\n",
      " 'example': 8,\n",
      " 'lik': 0.06393328805971461,\n",
      " 'model': 'pedagogical',\n",
      " 'pD': [(1, 0.07050694086392065),\n",
      "        (2, 0.0),\n",
      "        (3, 0.0),\n",
      "        (4, 0.07050694086392065),\n",
      "        (7, 0.07050694086392065),\n",
      "        (8, 0.06393328805971461),\n",
      "        (9, 0.06393328805971461),\n",
      "        (10, 0.07050694086392065),\n",
      "        (13, 0.04906615817640507),\n",
      "        (16, 0.04906615817640507),\n",
      "        (19, 0.04906615817640507),\n",
      "        (22, 0.04906615817640507),\n",
      "        (25, 0.07050694086392065),\n",
      "        (26, 0.04906615817640507),\n",
      "        (27, 0.06274710608717998),\n",
      "        (28, 0.07050694086392065),\n",
      "        (31, 0.07050694086392065),\n",
      "        (32, 0.0),\n",
      "        (33, 0.0),\n",
      "        (34, 0.07050694086392065)],\n",
      " 'pH': [('A', 0.31966637719365176),\n",
      "        ('B', 0.28409742653588654),\n",
      "        ('C', 0.0),\n",
      "        ('D', 0.3962361962704616)],\n",
      " 'pTrue': 0.31966637719365176,\n",
      " 'problem': 22,\n",
      " 'run': 1,\n",
      " 'subject': 1}\n"
     ]
    }
   ],
   "source": [
    "pedagogical_predictions = []\n",
    "nIter=10\n",
    "for name, group in human_df.groupby(['subject', 'run', 'block_idx']):\n",
    "    pred = fit_pedagogical_sampling(group, nIter=nIter)\n",
    "    pedagogical_predictions += pred\n",
    "    \n",
    "pprint.pprint(pedagogical_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model_predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(pedagogical_predictions, 'outputs/model_predictions_pedagogical_n%i.json' % nIter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py3]",
   "language": "python",
   "name": "conda-env-.conda-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
